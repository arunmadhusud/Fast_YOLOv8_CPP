{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "dMW25S9I6R0n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiEx51llymbK"
      },
      "outputs": [],
      "source": [
        "# Required imports. Please execute this cell first.\n",
        "%pip install -q \"tensorflow-macos>=2.5; sys_platform == 'darwin' and platform_machine == 'arm64'\"\n",
        "%pip install -q \"tensorflow>=2.5; sys_platform == 'darwin' and platform_machine != 'arm64'\"\n",
        "%pip install -q \"tensorflow>=2.5; sys_platform != 'darwin'\"\n",
        "%pip install -q --no-deps \"tensorflow-hub\"\n",
        "%pip install -q \"openvino>=2024.4.0\" \"nncf>=2.9.0\" \"requests\" \"transformers>=4.31\" \"onnx!=1.16.2\" \"tf_keras\"\n",
        "%pip install -q \"torch>=2.1\" \"torchvision>=0.16\" \"ultralytics==8.3.59\" onnx tqdm opencv-python --extra-index-url https://download.pytorch.org/whl/cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Export"
      ],
      "metadata": {
        "id": "21v0qOQ_6jxD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gf4qB_tUymbL"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "if not Path(\"notebook_utils.py\").exists():\n",
        "    r = requests.get(\n",
        "        url=\"https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py\",\n",
        "    )\n",
        "    open(\"notebook_utils.py\", \"w\").write(r.text)\n",
        "\n",
        "from notebook_utils import download_file, VideoPlayer, device_widget, quantization_widget\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "DET_MODEL_NAME = \"yolov8n\"\n",
        "\n",
        "det_model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Export the model to onnx\n",
        "det_model.export(format=\"onnx\", opset=17, simplify=True, dynamic=False, imgsz=640)"
      ],
      "metadata": {
        "id": "QW_0Yc5Iq_J-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a877IT3ymbM"
      },
      "outputs": [],
      "source": [
        "import openvino as ov\n",
        "\n",
        "# ov.convert_model returns an openvino.runtime.Model object\n",
        "ONNX_CV_MODEL_PATH = \"/content/yolov8n.onnx\"\n",
        "ov_model = ov.convert_model(ONNX_CV_MODEL_PATH)\n",
        "\n",
        "# then model can be serialized to *.xml & *.bin files\n",
        "# By default, the model will be saved as fp16 type. But check if your CPU supports FP16 operations, if not it will add additional overhead.\n",
        "ov.save_model(ov_model, \"/content/models/yolov8n_openvino_model/yolov8n.xml\",compress_to_fp16=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Static Quantization using nncf"
      ],
      "metadata": {
        "id": "hUTGzXDc63wz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code uses Ultralytics to define the calibration data loader for quantization. However, you can create a custom DataLoader using PyTorch if needed.Refer to the PyTorch documentation for details on how to create a DataLoader."
      ],
      "metadata": {
        "id": "FIur2gwKvVAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "from ultralytics.data.utils import DATASETS_DIR\n",
        "\n",
        "\n",
        "DATA_URL = \"http://images.cocodataset.org/zips/val2017.zip\"\n",
        "LABELS_URL = \"https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017labels-segments.zip\"\n",
        "CFG_URL = \"https://raw.githubusercontent.com/ultralytics/ultralytics/v8.1.0/ultralytics/cfg/datasets/coco.yaml\"\n",
        "\n",
        "OUT_DIR = DATASETS_DIR\n",
        "\n",
        "DATA_PATH = OUT_DIR / \"val2017.zip\"\n",
        "LABELS_PATH = OUT_DIR / \"coco2017labels-segments.zip\"\n",
        "CFG_PATH = OUT_DIR / \"coco.yaml\"\n",
        "\n",
        "if not (OUT_DIR / \"coco/labels\").exists():\n",
        "    download_file(DATA_URL, DATA_PATH.name, DATA_PATH.parent)\n",
        "    download_file(LABELS_URL, LABELS_PATH.name, LABELS_PATH.parent)\n",
        "    download_file(CFG_URL, CFG_PATH.name, CFG_PATH.parent)\n",
        "    with ZipFile(LABELS_PATH, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(OUT_DIR)\n",
        "    with ZipFile(DATA_PATH, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(OUT_DIR / \"coco/images\")"
      ],
      "metadata": {
        "id": "P8pVelICpKk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics.utils import DEFAULT_CFG\n",
        "from ultralytics.cfg import get_cfg\n",
        "from ultralytics.data.converter import coco80_to_coco91_class\n",
        "from ultralytics.data.utils import check_det_dataset\n",
        "\n",
        "args = get_cfg(cfg=DEFAULT_CFG)\n",
        "args.data = str(CFG_PATH)"
      ],
      "metadata": {
        "id": "jHBQ9Q9Uqc3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "det_validator = det_model.task_map[det_model.task][\"validator\"](args=args)"
      ],
      "metadata": {
        "id": "XVtWCgVCqent"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "det_validator.data = check_det_dataset(args.data)\n",
        "det_validator.stride = 32\n",
        "det_data_loader = det_validator.get_dataloader(OUT_DIR / \"coco\", 1)"
      ],
      "metadata": {
        "id": "TzBXBN-arQVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nncf\n",
        "from typing import Dict\n",
        "\n",
        "\n",
        "def transform_fn(data_item:Dict):\n",
        "    \"\"\"\n",
        "    Quantization transform function. Extracts and preprocess input data from dataloader item for quantization.\n",
        "    Parameters:\n",
        "       data_item: Dict with data item produced by DataLoader during iteration\n",
        "    Returns:\n",
        "        input_tensor: Input data for quantization\n",
        "    \"\"\"\n",
        "    input_tensor = det_validator.preprocess(data_item)['img'].numpy()\n",
        "    return input_tensor\n",
        "\n",
        "\n",
        "quantization_dataset = nncf.Dataset(det_data_loader, transform_fn)"
      ],
      "metadata": {
        "id": "QnOZLjiOrWkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For more accurate results, keep the operation in the postprocessing subgraph in floating point precision, using the ignored_scope parameter. You can visualize the model graph using https://netron.app for finding the names of nodes in in the postprocessing subgraph"
      ],
      "metadata": {
        "id": "AJ9_3TSA9XOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ignored_scope = nncf.IgnoredScope( # post-processing\n",
        "    subgraphs=[\n",
        "        nncf.Subgraph(inputs=['/model.22/Concat',\n",
        "                              '/model.22/Concat_1',\n",
        "                              '/model.22/Concat_2',\n",
        "                              '/model.22/Concat_3',\n",
        "                              '/model.22/Concat_4'],\n",
        "                      outputs=['output0'])\n",
        "    ]\n",
        ")\n",
        "\n",
        "# nncf.QuantizationPreset.MIXED symmetric quantization of weights and asymmetric quantization of activations.\n",
        "quantized_det_model = nncf.quantize(\n",
        "    ov_model,\n",
        "    quantization_dataset,\n",
        "    preset=nncf.QuantizationPreset.MIXED,\n",
        "    ignored_scope=ignored_scope\n",
        ")"
      ],
      "metadata": {
        "id": "wJ023fpIrcFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ov.save_model(quantized_det_model, \"/content/models/yolov8n_openvino_int8_model/yolov8n_int8.xml\",compress_to_fp16=False)"
      ],
      "metadata": {
        "id": "087NJVYMrz_K"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "openvino_notebooks": {
      "imageUrl": "",
      "tags": {
        "categories": [
          "Convert",
          "API Overview"
        ],
        "libraries": [],
        "other": [],
        "tasks": [
          "Image Classification",
          "Text Classification"
        ]
      }
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}